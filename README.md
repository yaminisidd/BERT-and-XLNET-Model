# BERT-and-XLNET-Model
Using the transformers of BERT and XLNET did the text classification
This project demonstrates how to perform text classification using BERT and XLNet models on the Yelp Dataset. The Yelp Dataset consists of customer reviews and star ratings for various businesses.

Requirements
Python 3.x
TensorFlow 2.x
Hugging Face Transformers library
Yelp Dataset
Download the Yelp Dataset from Yelp Dataset Challenge. Extract the dataset files and place them in the data directory.
Configuration
You can modify the training parameters, model architecture, and dataset paths by editing the configuration file config.py.
Results
The trained models will be saved in the models directory.
The evaluation results will be printed in the console and saved in the results directory.
License
This project is licensed under the MIT License.

Acknowledgments
The implementation is based on the Hugging Face Transformers library. For more information, refer to their documentation.
References
Yelp Dataset Challenge
BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
XLNet: Generalized Autoregressive Pretraining for Language Understanding
